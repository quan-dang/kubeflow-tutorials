{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cc06b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kfp==1.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23f1e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "import kfp\n",
    "from kfp.components import InputPath, InputTextFile, OutputPath, OutputTextFile\n",
    "from kfp.components import func_to_container_op\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from constants import NAMESPACE, HOST\n",
    "from utils.auth import get_session_cookie\n",
    "from utils import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5675f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b54257",
   "metadata": {},
   "source": [
    "### Define several constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d6a61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"tutorial\"\n",
    "PIPELINE_NAME = \"linear regression\"\n",
    "PIPELINE_VERSION = \"0.0.1\" # remember to change every run\n",
    "PIPELINE_DESCRIPTION = \"Using linear regression to predict house prices\"\n",
    "DATASET_URL = \"https://raw.githubusercontent.com/quan-dang/kubeflow-tutorials/master/data/housing.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850f9d26",
   "metadata": {},
   "source": [
    "### Create components from func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e77f01e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(\n",
    "    url: str,\n",
    "    X_train_path: OutputPath('PKL'),\n",
    "    y_train_path: OutputPath('PKL'),\n",
    "    X_val_path: OutputPath('PKL'),\n",
    "    y_val_path: OutputPath('PKL'),\n",
    "    X_test_path: OutputPath('PKL'),\n",
    "    y_test_path: OutputPath('PKL'),\n",
    "):\n",
    "    import pandas as pd\n",
    "    import wget\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import joblib\n",
    "    \n",
    "    # download housing.csv to local\n",
    "    wget.download(url)\n",
    "\n",
    "    df = pd.read_csv(\"housing.csv\")\n",
    "    X = df.drop(columns=[\"price\"])\n",
    "    y = df[\"price\"]\n",
    "\n",
    "    # create train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    # continue to split train set into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "        \n",
    "    # dump data to pkl\n",
    "    joblib.dump(X_train, X_train_path)\n",
    "    joblib.dump(y_train, y_train_path)\n",
    "    joblib.dump(X_val, X_val_path)\n",
    "    joblib.dump(y_val, y_val_path)\n",
    "    joblib.dump(X_test, X_test_path)\n",
    "    joblib.dump(y_test, y_test_path)\n",
    "    \n",
    "prepare_data_op = func_to_container_op(\n",
    "    func=prepare_data, \n",
    "   packages_to_install=[\"scikit-learn==1.0.2\", \n",
    "                        \"joblib==1.1.0\",\n",
    "                        \"pandas==1.3.5\",\n",
    "                        \"wget==3.2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a8c9509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    X_train_path: InputPath('PKL'),\n",
    "    y_train_path: InputPath('PKL'),\n",
    "    X_val_path: InputPath('PKL'),\n",
    "    y_val_path: InputPath('PKL'),\n",
    "    clf_path: OutputPath('Model')\n",
    "):\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.metrics import r2_score\n",
    "    import joblib\n",
    "\n",
    "    # load data\n",
    "    X_train = joblib.load(X_train_path)\n",
    "    y_train = joblib.load(y_train_path)\n",
    "    X_val = joblib.load(X_val_path)\n",
    "    y_val = joblib.load(y_val_path)\n",
    "    \n",
    "    categorical_features = X_train.loc[:, X_train.dtypes == object].columns\n",
    "\n",
    "    categorical_transformer = OneHotEncoder()\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "        ],\n",
    "        remainder = 'passthrough'\n",
    "    )\n",
    "\n",
    "    clf = Pipeline(\n",
    "        steps=[(\"preprocessor\", preprocessor), (\"regressor\", LinearRegression())]\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # make prediction on the val data\n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    # evaluate on the val data\n",
    "    print(\"r2_score: \", r2_score(y_val, y_val_pred))\n",
    "    \n",
    "    joblib.dump(clf, clf_path)\n",
    "    \n",
    "train_op = func_to_container_op(\n",
    "    func=train, \n",
    "    packages_to_install=[\"scikit-learn==1.0.2\", \n",
    "                        \"joblib==1.1.0\",\n",
    "                        \"pandas==1.3.5\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33796c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    X_test_path: InputPath('PKL'),\n",
    "    y_test_path: InputPath('PKL'),\n",
    "    clf_path: InputPath('Model'),\n",
    "    y_test_pred_path: OutputPath('PKL')\n",
    ") -> NamedTuple('Outputs', [\n",
    "  ('mlpipeline_metrics', 'Metrics'),\n",
    "]):\n",
    "    import joblib\n",
    "    from sklearn.metrics import r2_score\n",
    "    import json\n",
    "    \n",
    "    # load data\n",
    "    X_test = joblib.load(X_test_path)\n",
    "    y_test = joblib.load(y_test_path)\n",
    "    \n",
    "    # load model\n",
    "    clf = joblib.load(clf_path)\n",
    "    \n",
    "    # make prediction on the test data\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    \n",
    "    joblib.dump(y_test_pred, y_test_pred_path)\n",
    "    \n",
    "    # evaluate on the test data\n",
    "    metrics = {\n",
    "        'metrics': [{\n",
    "            'name': 'r2_score', # The name of the metric. Visualized as the column name in the runs table.\n",
    "            'numberValue':  r2_score(y_test, y_test_pred), # The value of the metric. Must be a numeric value.\n",
    "            'format': \"RAW\",   # The optional format of the metric. Supported values are \"RAW\" (displayed in raw format) and \"PERCENTAGE\" (displayed in percentage format).\n",
    "        }]\n",
    "    }\n",
    "    return [json.dumps(metrics)]\n",
    "        \n",
    "evaluate_op = func_to_container_op(\n",
    "    func=evaluate, \n",
    "    packages_to_install=[\"scikit-learn==1.0.2\", \n",
    "                        \"joblib==1.1.0\",\n",
    "                        \"pandas==1.3.5\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3cdb19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(\n",
    "    X_test_path: InputPath('PKL'),\n",
    "    y_test_path: InputPath('PKL'),\n",
    "    y_test_pred_path: InputPath('PKL'),\n",
    "    mlpipeline_ui_metadata_path: kfp.components.OutputPath(),\n",
    "):\n",
    "    import joblib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import base64\n",
    "    from io import BytesIO\n",
    "    import json\n",
    "    \n",
    "    # load data\n",
    "    X_test = joblib.load(X_test_path)\n",
    "    y_test = joblib.load(y_test_path)\n",
    "    y_test_pred = joblib.load(y_test_pred_path)\n",
    "    \n",
    "    ncols = 4\n",
    "    nrows = 3\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(10, 5),\n",
    "                            constrained_layout=True)\n",
    "\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            # corresponding feature index to this subplot\n",
    "            feature_index = row*nrows + col\n",
    "            axs[row, col].scatter(X_test.iloc[:,feature_index], y_test, color=\"red\")\n",
    "            axs[row, col].scatter(X_test.iloc[:,feature_index], y_test_pred, color=\"blue\")\n",
    "            axs[row, col].set_title(X_test.columns[feature_index])\n",
    "\n",
    "    fig.suptitle('Test data')\n",
    "    \n",
    "    # Ref: https://stackoverflow.com/questions/48717794/matplotlib-embed-figures-in-auto-generated-html\n",
    "    tmpfile = BytesIO()\n",
    "    fig.savefig(tmpfile, format='png')\n",
    "    encoded = base64.b64encode(tmpfile.getvalue()).decode('utf-8')\n",
    "    html = '<img src=\\'data:image/png;base64,{}\\'>'.format(encoded)\n",
    "\n",
    "    with open('test.html','w') as f:\n",
    "        f.write(html)\n",
    "\n",
    "    metadata = {\n",
    "        'outputs' : [{\n",
    "          'type': 'web-app',\n",
    "          'storage': 'inline',\n",
    "          'source': html,\n",
    "        }]\n",
    "    }\n",
    "\n",
    "    with open(mlpipeline_ui_metadata_path, 'w') as metadata_file:\n",
    "        json.dump(metadata, metadata_file)\n",
    "    \n",
    "    \n",
    "visualize_op = func_to_container_op(\n",
    "    func=visualize,\n",
    "    packages_to_install=[\"matplotlib==3.5.1\", \n",
    "                        \"joblib==1.1.0\",\n",
    "                        \"pandas==1.3.5\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd88bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline and create a task from a component:\n",
    "def my_pipeline(url):\n",
    "    prepare_data_task = prepare_data_op(url=url)\n",
    "    train_task = train_op(x_train=prepare_data_task.outputs['X_train'], \n",
    "                       y_train=prepare_data_task.outputs['y_train'],\n",
    "                       x_val=prepare_data_task.outputs['X_val'],\n",
    "                       y_val=prepare_data_task.outputs['y_val'],\n",
    "                      )\n",
    "    evaluate_task = evaluate_op(x_test=prepare_data_task.outputs['X_test'], \n",
    "                            y_test=prepare_data_task.outputs['y_test'],\n",
    "                            clf=train_task.outputs['clf'])\n",
    "    visualize_task = visualize_op(x_test=prepare_data_task.outputs['X_test'], \n",
    "                            y_test=prepare_data_task.outputs['y_test'],\n",
    "                            y_test_pred=evaluate_task.outputs['y_test_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0a15d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"http://10.10.10.10:8080//pipeline/#/experiments/details/ae3df007-d63b-46f1-8ab6-67a4bab5af63\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://10.10.10.10:8080//pipeline/#/runs/details/974d04c1-22df-41c9-addf-8a18ec45282e\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=974d04c1-22df-41c9-addf-8a18ec45282e)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_cookie = get_session_cookie()\n",
    "client = kfp.Client(\n",
    "    host=f\"{HOST}/pipeline\",\n",
    "    cookies=f\"authservice_session={session_cookie}\",\n",
    "    namespace=NAMESPACE,\n",
    ")\n",
    "client.create_run_from_pipeline_func(\n",
    "    my_pipeline,\n",
    "    arguments={\n",
    "        'url': DATASET_URL\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
